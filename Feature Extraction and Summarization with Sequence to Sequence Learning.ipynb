{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Feature Extraction and Summarization with Sequence to Sequence Learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/hamelsmu/kdd-2018-hands-on-tutorials/blob/master/Feature%20Extraction%20and%20Summarization%20with%20Sequence%20to%20Sequence%20Learning.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Q-gKT37Didb7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Setup Notebook\n",
        "\n",
        "Install [ktext](https://github.com/hamelsmu/ktext) and [annoy](https://github.com/spotify/annoy)."
      ]
    },
    {
      "metadata": {
        "id": "E7l80u-0fyHK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -q ktext\n",
        "!pip install -q annoy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W-KjInFk0v8l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "79797b91-0227-4501-d642-d476a5e52f40"
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "from urllib.request import urlopen\n",
        "\n",
        "from annoy import AnnoyIndex\n",
        "from keras import optimizers\n",
        "from keras.layers import Input, Dense, LSTM, GRU, Embedding, Lambda, BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from ktext.preprocess import processor\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "iZzcs-PDPZqn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data sets"
      ]
    },
    {
      "metadata": {
        "id": "oQLV9P8h0v8q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## [English to French](http://www.manythings.org/anki/)"
      ]
    },
    {
      "metadata": {
        "id": "1uK2D4090v8r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# !wget http://www.manythings.org/anki/fra-eng.zip\n",
        "# !unzip -o fra-eng.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8UMp9B4M0v8u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# with open('fra.txt', 'r') as f:\n",
        "#     lines = f.readlines()\n",
        "# target_docs, source_docs = zip(*[line.strip().split('\\t') for line in lines])\n",
        "# target_docs = list(set(target_docs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "McfeOLlh0v8x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## [CoNaLa](https://conala-corpus.github.io/)"
      ]
    },
    {
      "metadata": {
        "id": "JAAOUd-k0v8x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "d9a8afaa-e447-4042-a55c-d030720f1cfd"
      },
      "cell_type": "code",
      "source": [
        "!wget http://www.phontron.com/download/conala-corpus-v1.1.zip\n",
        "!unzip -o conala-corpus-v1.1.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-08-07 17:41:27--  http://www.phontron.com/download/conala-corpus-v1.1.zip\n",
            "Resolving www.phontron.com (www.phontron.com)... 208.113.196.149\n",
            "Connecting to www.phontron.com (www.phontron.com)|208.113.196.149|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 52105440 (50M) [application/zip]\n",
            "Saving to: ‘conala-corpus-v1.1.zip.1’\n",
            "\n",
            "conala-corpus-v1.1. 100%[===================>]  49.69M  45.7MB/s    in 1.1s    \n",
            "\n",
            "2018-08-07 17:41:28 (45.7 MB/s) - ‘conala-corpus-v1.1.zip.1’ saved [52105440/52105440]\n",
            "\n",
            "Archive:  conala-corpus-v1.1.zip\n",
            "  inflating: conala-corpus/conala-mined.jsonl  \n",
            "  inflating: conala-corpus/conala-train.json  \n",
            "  inflating: conala-corpus/conala-test.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hFzeLKxg0v81",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('conala-corpus/conala-mined.jsonl', 'r') as f:\n",
        "    lines = [json.loads(line) for line in f.readlines()]\n",
        "source_docs = [line['snippet'] for line in lines]\n",
        "target_docs = [line['intent'] for line in lines]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QsXzuRH50v83",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('conala-corpus/conala-train.json', 'r') as f:\n",
        "    lines = json.load(f)\n",
        "train_source_docs = [line['snippet'] for line in lines]\n",
        "train_target_docs = [line['intent'] for line in lines]\n",
        "test_docs = [line['rewritten_intent'] for line in lines if line['rewritten_intent']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-t0x8A5w0v87",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open('conala-corpus/conala-test.json', 'r') as f:\n",
        "    lines = json.load(f)\n",
        "test_source_docs = [line['snippet'] for line in lines]\n",
        "test_target_docs = [line['intent'] for line in lines]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EhmB0qpr3RD5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Other Data Sources (For Later Use)"
      ]
    },
    {
      "metadata": {
        "id": "bw33N_AcPZqp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GitHub issues data"
      ]
    },
    {
      "metadata": {
        "id": "GSR2uek3PZqq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# issues = pd.read_csv('https://storage.googleapis.com/kubeflow-examples/github-issue-summarization-data/github-issues.zip')\n",
        "# source_docs = list(issues.body)\n",
        "# target_docs = list(issues.issue_title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AP58__OgPZqt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Python functions data"
      ]
    },
    {
      "metadata": {
        "id": "izpU8EXGPZqu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# f = urlopen('https://storage.googleapis.com/kubeflow-examples/code_search/data/train.function')\n",
        "# source_docs = [line.decode('utf-8') for line in f.readlines()]\n",
        "# f = urlopen('https://storage.googleapis.com/kubeflow-examples/code_search/data/train.docstring')\n",
        "# target_docs = [line.decode('utf-8') for line in f.readlines()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8JykNMln0v9I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Use subset of the data\n",
        "\n",
        "We will use only of the training set in the interest of brevity.  However, we can use the full dataset in a subsequent pass if desired."
      ]
    },
    {
      "metadata": {
        "id": "Hj1tDqDFPZqx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "source_docs = source_docs[:100000]\n",
        "target_docs = target_docs[:100000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lxYjchOjPZqz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Language Model"
      ]
    },
    {
      "metadata": {
        "id": "COkelzEXPZq0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocessing\n",
        "Tokenize, generate vocabulary, apply padding and vectorize."
      ]
    },
    {
      "metadata": {
        "id": "hT8NcmEU4C4A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lets inspect the raw text of the target docs.  "
      ]
    },
    {
      "metadata": {
        "id": "Ww4AHHUX4CPL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "5ac26a60-2582-432c-a873-10a35c1a1d96"
      },
      "cell_type": "code",
      "source": [
        "target_docs[:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sort a nested list by two elements',\n",
              " 'converting integer to list in python',\n",
              " 'Converting byte string in unicode string',\n",
              " 'List of arguments with argparse',\n",
              " 'How to convert a Date string to a DateTime object?',\n",
              " 'How to efficiently convert Matlab engine arrays to numpy ndarray?',\n",
              " 'Converting html to text with Python',\n",
              " 'regex for repeating words in a string in Python',\n",
              " 'Ordering a list of dictionaries in python',\n",
              " 'Two Combination Lists from One List']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "LTxQMjaa4WsL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In order to pre-process this text for deep learning, we need to convert this text into integer values.  In order to do this, we will use the `ktext` package."
      ]
    },
    {
      "metadata": {
        "id": "uHOMxrONPZq3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f6a24e25-1cf5-4716-9b03-5e4e7f7ef3ca"
      },
      "cell_type": "code",
      "source": [
        "proc = processor(hueristic_pct_padding=.7, keep_n=20000)\n",
        "vecs = proc.fit_transform(target_docs)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:....tokenizing data\n",
            "WARNING:root:Setting maximum document length to 10 based upon hueristic of 0.7 percentile.\n",
            " See full histogram by insepecting the `document_length_stats` attribute.\n",
            "WARNING:root:(1/2) done. 24 sec\n",
            "WARNING:root:....building corpus\n",
            "WARNING:root:(2/2) done. 0 sec\n",
            "WARNING:root:Finished parsing 100,000 documents.\n",
            "WARNING:root:...fit is finished, beginning transform\n",
            "WARNING:root:...padding data\n",
            "WARNING:root:done. 1 sec\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "0jld4HT0Dp_r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Below is an example where tokens are mapped to integers"
      ]
    },
    {
      "metadata": {
        "id": "-ogmGKqUC-Jd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0b965415-bbfb-400b-ef0b-38bad4b40166"
      },
      "cell_type": "code",
      "source": [
        "print('original list: ', target_docs[0].split())\n",
        "print('tokenized list: ', [proc.token2id[x] for x in target_docs[0].lower().split()])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original list:  ['Sort', 'a', 'nested', 'list', 'by', 'two', 'elements']\n",
            "tokenized list:  [118, 2, 151, 10, 43, 38, 56]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ldna19QcEXYp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can see the most common words here, by calling the `token_count_pandas() method`. "
      ]
    },
    {
      "metadata": {
        "id": "dNOluhQpD8Fq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "outputId": "733448c4-1bb4-4c32-de05-5e2a88c6be0d"
      },
      "cell_type": "code",
      "source": [
        "proc.token_count_pandas().head(20)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>a</th>\n",
              "      <td>52824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>python</th>\n",
              "      <td>48171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>in</th>\n",
              "      <td>47702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>47281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>how</th>\n",
              "      <td>36116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>of</th>\n",
              "      <td>22831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>with</th>\n",
              "      <td>15954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>the</th>\n",
              "      <td>13505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>list</th>\n",
              "      <td>12651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>from</th>\n",
              "      <td>11626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>i</th>\n",
              "      <td>9902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>using</th>\n",
              "      <td>8372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>string</th>\n",
              "      <td>7917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>and</th>\n",
              "      <td>7140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>number</th>\n",
              "      <td>6636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>file</th>\n",
              "      <td>6383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>do</th>\n",
              "      <td>6142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pandas</th>\n",
              "      <td>6108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>for</th>\n",
              "      <td>5724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>matplotlib</th>\n",
              "      <td>5640</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            count\n",
              "a           52824\n",
              "python      48171\n",
              "in          47702\n",
              "to          47281\n",
              "how         36116\n",
              "of          22831\n",
              "with        15954\n",
              "the         13505\n",
              "list        12651\n",
              "from        11626\n",
              "i            9902\n",
              "using        8372\n",
              "string       7917\n",
              "and          7140\n",
              "number       6636\n",
              "file         6383\n",
              "do           6142\n",
              "pandas       6108\n",
              "for          5724\n",
              "matplotlib   5640"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "Ab3JU2L5Ey9_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Furthermore, the documents in our corpus have different lengths.  By setting `hueristic_pct_padding=.7`, `ktext` will truncate and pad all sequences to the 70th percentile length.  However, it can be useful to sanity check a histogram of lengths.  We inspect the `document_length_stats` property below which displays a histogram of document lengths. "
      ]
    },
    {
      "metadata": {
        "id": "ZIH4R1HREiTO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "c0681a77-1388-4bf7-8b0b-a40491af0060"
      },
      "cell_type": "code",
      "source": [
        "proc.document_length_stats"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bin</th>\n",
              "      <th>doc_count</th>\n",
              "      <th>cumsum_pct</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>0.00031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>34978</td>\n",
              "      <td>0.35009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>50700</td>\n",
              "      <td>0.85709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15</td>\n",
              "      <td>12664</td>\n",
              "      <td>0.98373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20</td>\n",
              "      <td>1486</td>\n",
              "      <td>0.99859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>25</td>\n",
              "      <td>124</td>\n",
              "      <td>0.99983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30</td>\n",
              "      <td>17</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   bin  doc_count  cumsum_pct\n",
              "6    0         31     0.00031\n",
              "0    5      34978     0.35009\n",
              "1   10      50700     0.85709\n",
              "2   15      12664     0.98373\n",
              "3   20       1486     0.99859\n",
              "5   25        124     0.99983\n",
              "4   30         17     1.00000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "SCNn24hRDxeF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It is useful to keep track of the maximum length and the unique number of tokens in the corpus for later purposes."
      ]
    },
    {
      "metadata": {
        "id": "wnjhEa-NPZq6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b8ba0fb6-d471-440c-ed77-21e6e19670fe"
      },
      "cell_type": "code",
      "source": [
        "vocab_size = max(proc.id2token.keys()) + 1\n",
        "max_length = proc.padding_maxlen\n",
        "\n",
        "print('vocab size: ', vocab_size)\n",
        "print('max length allowed for documents: ', max_length)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vocab size:  10225\n",
            "max length allowed for documents:  10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "srQ2EApW0v9X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Language model"
      ]
    },
    {
      "metadata": {
        "id": "V31lnrq70v9T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Prepare training data for language model."
      ]
    },
    {
      "metadata": {
        "id": "Ioq7Sd9EPZq8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8354163-fdb4-4134-d186-034f60d82a28"
      },
      "cell_type": "code",
      "source": [
        "sequences = []\n",
        "for arr in tqdm(vecs):\n",
        "    non_zero = (arr != 0).argmax()\n",
        "    for i in range(non_zero, len(arr)):\n",
        "        sequences.append(arr[:i+1])\n",
        "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n",
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "# y = to_categorical(y, num_classes=vocab_size)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:01<00:00, 93113.13it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "WKW7TCl6PZq_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "2fa7bb51-f917-4cdc-c568-8434929b1843"
      },
      "cell_type": "code",
      "source": [
        "i = Input(shape=(max_length-1,))\n",
        "x = Embedding(vocab_size, 256, input_length=max_length-1)(i)\n",
        "x = LSTM(256, return_sequences=True)(x)\n",
        "last_timestep = Lambda(lambda x: x[:, -1, :])(x)\n",
        "last_timestep = Dense(vocab_size, activation='softmax')(last_timestep)\n",
        "model = Model(i, last_timestep)\n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 9)                 0         \n",
            "_________________________________________________________________\n",
            "embedding_4 (Embedding)      (None, 9, 256)            2617600   \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 9, 256)            525312    \n",
            "_________________________________________________________________\n",
            "lambda_4 (Lambda)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10225)             2627825   \n",
            "=================================================================\n",
            "Total params: 5,770,737\n",
            "Trainable params: 5,770,737\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jnVeYIZV0v9a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ]
    },
    {
      "metadata": {
        "id": "Psve_dWVPZrB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "c2dabb37-308a-45ad-affb-fc812b687db4"
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X, y, epochs=10, batch_size=50, validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 734247 samples, validate on 81584 samples\n",
            "Epoch 1/10\n",
            "734247/734247 [==============================] - 622s 847us/step - loss: 4.6589 - acc: 0.2620 - val_loss: 4.1240 - val_acc: 0.3241\n",
            "Epoch 2/10\n",
            "734247/734247 [==============================] - 618s 841us/step - loss: 3.4083 - acc: 0.3971 - val_loss: 3.5445 - val_acc: 0.4057\n",
            "Epoch 3/10\n",
            "421850/734247 [================>.............] - ETA: 4:14 - loss: 2.8927 - acc: 0.4744"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cFH1DmGHPZrE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate sequence\n",
        "\n",
        "The goal of a language model is to predict the next word in a sequence.  To sanity check the language model, we will see what kind of sentence is generated when we start with a a seed word of 'is'.  We are looking to see if the sentence generated appears to be sampled from the distribution of the "
      ]
    },
    {
      "metadata": {
        "id": "2R-2I_HRPZrE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_seq(model, proc, n_words, seed_text):\n",
        "    in_text = seed_text\n",
        "    for _ in range(n_words):\n",
        "        vec = proc.transform([in_text])[:,1:]\n",
        "        index = np.argmax(model.predict(vec, verbose=0), axis=1)[0]\n",
        "        out_word = ''\n",
        "        if index == 1:\n",
        "            out_word = '_unk_'\n",
        "        else:\n",
        "            out_word = proc.id2token[index]\n",
        "        in_text += ' ' + out_word\n",
        "    return in_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8wpHSxIOPZrH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34d82c2d-6562-4d3a-926b-ee7da789a91d"
      },
      "cell_type": "code",
      "source": [
        "generate_seq(model, proc, max_length, 'is')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'there python is there a way to make the tkinter text'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "zzNZqTqVPZrJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate embeddings"
      ]
    },
    {
      "metadata": {
        "id": "Y-Rig9cePZrM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_model = Model(inputs=model.inputs, outputs=model.layers[-3].output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X-FFznLQPZrO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "0b979367-cd20-44f4-9f2c-9b7447170e9b"
      },
      "cell_type": "code",
      "source": [
        "input_sequence = test_docs[random.randint(0, len(test_docs))]\n",
        "print(input_sequence)\n",
        "vec = proc.transform([input_sequence])[:,1:]\n",
        "embedding_model.predict(vec)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check if list `li` is empty\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.        , -0.        ,  0.        , ...,  0.        ,\n",
              "          0.2822097 ,  0.        ],\n",
              "        [ 0.        , -0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.        , -0.        ,  0.        , ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        ...,\n",
              "        [ 0.55555606,  0.44329646, -0.6894753 , ..., -0.30388248,\n",
              "          0.        ,  0.56213903],\n",
              "        [ 0.        ,  0.7900059 , -0.22815275, ..., -0.7061561 ,\n",
              "          0.        ,  0.7455072 ],\n",
              "        [ 0.7805286 , -0.73729074, -0.9997308 , ..., -0.8817332 ,\n",
              "         -0.3556277 , -0.11047834]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "metadata": {
        "id": "haQjC19y0v9l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vecs = proc.transform(test_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rLeLELte0v9n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "hidden_states = embedding_model.predict(vecs[:, 1:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SCf0kjpr0v9p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mean_vecs = np.mean(hidden_states, axis=1)\n",
        "max_vecs = np.max(hidden_states, axis=1)\n",
        "sum_vecs = np.sum(hidden_states, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "giC48Kt00v9s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Applications\n",
        "### Build vector indices"
      ]
    },
    {
      "metadata": {
        "id": "afBInH4C0v9s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f2941af7-9018-4cb5-d863-90a64ca6b93b"
      },
      "cell_type": "code",
      "source": [
        "dimension = hidden_states.shape[-1]\n",
        "index = AnnoyIndex(dimension)\n",
        "for i, v in enumerate(sum_vecs):\n",
        "    index.add_item(i, v)\n",
        "index.build(10)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "pp2KAWNj0v9u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Search nearest neighbors"
      ]
    },
    {
      "metadata": {
        "id": "3zzMzXom0v9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1ae395ee-f897-4f27-aeb8-339ad0b66223"
      },
      "cell_type": "code",
      "source": [
        "ids, _ = index.get_nns_by_item(1000, 10, include_distances=True)\n",
        "[test_docs[i] for i in ids]"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['check if any of the items in  `search` appear in `string`',\n",
              " \"check if all of the following items in list `['a', 'b']` are in a list `['a', 'b', 'c']`\",\n",
              " 'check if any elements in one list `list1` are in another list `list2`',\n",
              " 'check if any item from list `b` is in list `a`',\n",
              " 'check if any element of list `substring_list` are in string `string`',\n",
              " 'Check if a given key `key` exists in dictionary `d`',\n",
              " \"Check if a given key 'key1' exists in dictionary `dict`\",\n",
              " \"test if either of strings `a` or `b` are members of the set of strings, `['b', 'a', 'foo', 'bar']`\",\n",
              " 'check if any values in a list `input_list` is a list',\n",
              " 'check if the third element of all the lists in a list \"items\" is equal to zero.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "tr_tKEDx0v9w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "780e511c-1bce-4f64-d434-09266a12c22d"
      },
      "cell_type": "code",
      "source": [
        "input_sequence = test_docs[random.randint(0, len(test_docs))]\n",
        "print(input_sequence)\n",
        "\n",
        "vec = proc.transform([input_sequence])[:,1:]\n",
        "vec = np.sum(embedding_model.predict(vec), axis=1)\n",
        "ids, _ = index.get_nns_by_vector(vec.T, 10, include_distances=True)\n",
        "[test_docs[i] for i in ids]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "interleave the elements of two lists `a` and `b`\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['interleave the elements of two lists `a` and `b`',\n",
              " 'sum the product of elements of two lists named `a` and `b`',\n",
              " 'get indexes of the largest `2` values from a list `a` using itemgetter',\n",
              " 'apply itertools.product to elements of a list of lists `arrays`',\n",
              " 'Find all the items from a dictionary `D` if the key contains the string `Light`',\n",
              " \"Concatenate elements of a list 'x' of multiple integers to a single integer\",\n",
              " \"get unique values from the list `['a', 'b', 'c', 'd']`\",\n",
              " 'get index of elements in array `A` that occur in another array `B`',\n",
              " 'insert elements of list `k` into list `a` at position `n`',\n",
              " 'get tuples of the corresponding elements from lists `lst` and `lst2`']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "metadata": {
        "id": "pnPW20o9PZrR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sequence to Sequence Model"
      ]
    },
    {
      "metadata": {
        "id": "BQsnI6720v9z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocessing\n",
        "Tokenize, generate vocabulary, apply padding and vectorize.\n",
        "If source and target are from the same distribution, vocabulary can be shared."
      ]
    },
    {
      "metadata": {
        "id": "s_nE-SeKPZrS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "source_proc = processor(hueristic_pct_padding=.7, keep_n=20000)\n",
        "source_vecs = source_proc.fit_transform(source_docs)\n",
        "\n",
        "target_proc = processor(append_indicators=True, hueristic_pct_padding=.7, keep_n=14000, padding ='post')\n",
        "target_vecs = target_proc.fit_transform(target_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3b0wFryNPZrU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_input_data = source_vecs\n",
        "encoder_seq_len = encoder_input_data.shape[1]\n",
        "\n",
        "decoder_input_data = target_vecs[:, :-1]\n",
        "decoder_target_data = target_vecs[:, 1:]\n",
        "\n",
        "num_encoder_tokens = max(source_proc.id2token.keys()) + 1\n",
        "num_decoder_tokens = max(target_proc.id2token.keys()) + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FCkBg1_1PZrZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Encoder model"
      ]
    },
    {
      "metadata": {
        "id": "nThkgdknPZra",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_emb_dim=512\n",
        "hidden_state_dim=1024\n",
        "encoder_seq_len=encoder_seq_len\n",
        "num_encoder_tokens=num_encoder_tokens\n",
        "num_decoder_tokens=num_decoder_tokens\n",
        "\n",
        "encoder_inputs = Input(shape=(encoder_seq_len,), name='Encoder-Input')\n",
        "x = Embedding(num_encoder_tokens, word_emb_dim, name='Body-Word-Embedding', mask_zero=False)(encoder_inputs)\n",
        "x = BatchNormalization(name='Encoder-Batchnorm-1')(x)\n",
        "_, state_h = GRU(hidden_state_dim, return_state=True, name='Encoder-Last-GRU', dropout=.5)(x)\n",
        "encoder_model = Model(inputs=encoder_inputs, outputs=state_h, name='Encoder-Model')\n",
        "seq2seq_encoder_out = encoder_model(encoder_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8PnsgReVPZre",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Decoder model"
      ]
    },
    {
      "metadata": {
        "id": "bu-KgmfjPZre",
        "colab_type": "code",
        "colab": {},
        "collapsed": true
      },
      "cell_type": "code",
      "source": [
        "decoder_inputs = Input(shape=(None,), name='Decoder-Input')\n",
        "dec_emb = Embedding(num_decoder_tokens, word_emb_dim, name='Decoder-Word-Embedding', mask_zero=False)(decoder_inputs)\n",
        "dec_bn = BatchNormalization(name='Decoder-Batchnorm-1')(dec_emb)\n",
        "decoder_gru = GRU(hidden_state_dim, return_state=True, return_sequences=True, name='Decoder-GRU', dropout=.5)\n",
        "decoder_gru_output, _ = decoder_gru(dec_bn, initial_state=seq2seq_encoder_out)\n",
        "x = BatchNormalization(name='Decoder-Batchnorm-2')(decoder_gru_output)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name='Final-Output-Dense')\n",
        "decoder_outputs = decoder_dense(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WfH-WvGwPZrg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Sequence to sequence model"
      ]
    },
    {
      "metadata": {
        "id": "xsNgKYlKPZri",
        "colab_type": "code",
        "colab": {},
        "collapsed": true
      },
      "cell_type": "code",
      "source": [
        "seq2seq_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WT8maZlD0v-A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ]
    },
    {
      "metadata": {
        "id": "HgUemXCbPZrk",
        "colab_type": "code",
        "colab": {},
        "collapsed": true
      },
      "cell_type": "code",
      "source": [
        "batch_size = 1024\n",
        "epochs = 16\n",
        "\n",
        "seq2seq_model.compile(optimizer=optimizers.Nadam(lr=0.00005), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = seq2seq_model.fit([encoder_input_data, decoder_input_data],\n",
        "                            np.expand_dims(decoder_target_data, -1),\n",
        "                            batch_size=batch_size,\n",
        "                            epochs=epochs,\n",
        "                            validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1lbdGPHE0v-B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Extract encoder and decoder models"
      ]
    },
    {
      "metadata": {
        "id": "UAqk3fIwPZrn",
        "colab_type": "code",
        "colab": {},
        "collapsed": true
      },
      "cell_type": "code",
      "source": [
        "def extract_decoder_model(model):\n",
        "    latent_dim = model.get_layer('Encoder-Model').output_shape[-1]\n",
        "    decoder_inputs = model.get_layer('Decoder-Input').input\n",
        "    dec_emb = model.get_layer('Decoder-Word-Embedding')(decoder_inputs)\n",
        "    dec_bn = model.get_layer('Decoder-Batchnorm-1')(dec_emb)\n",
        "    gru_inference_state_input = Input(shape=(latent_dim,), name='hidden_state_input')\n",
        "    gru_out, gru_state_out = model.get_layer('Decoder-GRU')([dec_bn, gru_inference_state_input])\n",
        "    dec_bn2 = model.get_layer('Decoder-Batchnorm-2')(gru_out)\n",
        "    dense_out = model.get_layer('Final-Output-Dense')(dec_bn2)\n",
        "    decoder_model = Model([decoder_inputs, gru_inference_state_input], [dense_out, gru_state_out])\n",
        "    return decoder_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xe0_KakGPZrp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "encoder_model = seq2seq_model.get_layer('Encoder-Model')\n",
        "for layer in encoder_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "decoder_model = extract_decoder_model(seq2seq_model)\n",
        "decoder_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZFdwR6UR0v-L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Predict sequence"
      ]
    },
    {
      "metadata": {
        "id": "JvK1eN9fPZrr",
        "colab_type": "code",
        "colab": {},
        "collapsed": true
      },
      "cell_type": "code",
      "source": [
        "i = random.randint(0, len(test_source_docs))\n",
        "\n",
        "max_len = target_proc.padding_maxlen\n",
        "raw_input_text = test_source_docs[i]\n",
        "\n",
        "raw_tokenized = source_proc.transform([raw_input_text])\n",
        "encoding = encoder_model.predict(raw_tokenized)\n",
        "original_encoding = encoding\n",
        "state_value = np.array(target_proc.token2id['_start_']).reshape(1, 1)\n",
        "\n",
        "decoded_sentence = []\n",
        "stop_condition = False\n",
        "while not stop_condition:\n",
        "    preds, st = decoder_model.predict([state_value, encoding])\n",
        "    pred_idx = np.argmax(preds[:, :, 2:]) + 2\n",
        "    pred_word_str = target_proc.id2token[pred_idx]\n",
        "\n",
        "    if pred_word_str == '_end_' or len(decoded_sentence) >= max_len:\n",
        "        stop_condition = True\n",
        "        break\n",
        "    decoded_sentence.append(pred_word_str)\n",
        "\n",
        "    # update the decoder for the next word\n",
        "    encoding = st\n",
        "    state_value = np.array(pred_idx).reshape(1, 1)\n",
        "\n",
        "print(raw_input_text)\n",
        "print(test_target_docs[i])\n",
        "print(' '.join(decoded_sentence))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1xgPRKJqPZrv",
        "colab_type": "code",
        "colab": {},
        "collapsed": true
      },
      "cell_type": "code",
      "source": [
        "## Generate Embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qYPM3Tqf0v-P",
        "colab_type": "code",
        "colab": {},
        "collapsed": true
      },
      "cell_type": "code",
      "source": [
        "train_source_emb = encoder_model.predict(source_proc.transform(train_source_docs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "geb3SOyk0v-Q",
        "colab_type": "code",
        "colab": {},
        "collapsed": true
      },
      "cell_type": "code",
      "source": [
        "vecs = proc.transform(train_target_docs)\n",
        "hidden_states = embedding_model.predict(vecs[:, 1:])\n",
        "mean_vecs = np.mean(hidden_states, axis=1)\n",
        "max_vecs = np.max(hidden_states, axis=1)\n",
        "sum_vecs = np.sum(hidden_states, axis=1)\n",
        "train_target_emb = sum_vecs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e_f5ptIL0v-R",
        "colab_type": "code",
        "colab": {},
        "collapsed": true
      },
      "cell_type": "code",
      "source": [
        "print(train_source_emb.shape)\n",
        "print(train_target_emb.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8xOKEWFj0v-S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Modality"
      ]
    },
    {
      "metadata": {
        "id": "-noqpPJY0v-T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inp = Input(shape=(train_source_emb.shape[1],))\n",
        "x = Dense(train_target_emb.shape[1], use_bias=False)(inp)\n",
        "# x = BatchNormalization()(x)\n",
        "# x = Dense(512)(x)\n",
        "modal_model = Model([inp], x)\n",
        "modal_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7zALzqWO0v-U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modal_model.compile(optimizer=optimizers.Nadam(lr=0.002), loss='cosine_proximity', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 1024\n",
        "epochs = 10\n",
        "history = modal_model.fit([train_source_emb], train_target_emb,\n",
        "                          batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Re8nxdPs0v-Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Applications\n",
        "### Use test data"
      ]
    },
    {
      "metadata": {
        "id": "ZX0AIo_B0v-Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_source_emb = encoder_model.predict(source_proc.transform(test_source_docs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2BaHfbsl0v-a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vecs = proc.transform(test_target_docs)\n",
        "hidden_states = embedding_model.predict(vecs[:, 1:])\n",
        "mean_vecs = np.mean(hidden_states, axis=1)\n",
        "max_vecs = np.max(hidden_states, axis=1)\n",
        "sum_vecs = np.sum(hidden_states, axis=1)\n",
        "test_target_emb = sum_vecs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QgKykGVh0v-b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(test_source_emb.shape)\n",
        "print(test_target_emb.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eg7JX1Vu0v-d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build vector indices"
      ]
    },
    {
      "metadata": {
        "id": "D7HKpc3j0v-d",
        "colab_type": "code",
        "colab": {},
        "collapsed": true
      },
      "cell_type": "code",
      "source": [
        "dimension = hidden_states.shape[-1]\n",
        "index = AnnoyIndex(dimension)\n",
        "for i, v in enumerate(test_target_emb):\n",
        "    index.add_item(i, v)\n",
        "index.build(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C-fpIqvQ0v-f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Search nearest neighbors"
      ]
    },
    {
      "metadata": {
        "id": "zPlMXs500v-g",
        "colab_type": "code",
        "colab": {},
        "collapsed": true
      },
      "cell_type": "code",
      "source": [
        "i = random.randint(0, len(test_source_docs))\n",
        "input_sequence = test_source_docs[i]\n",
        "print(input_sequence)\n",
        "\n",
        "vec = np.expand_dims(test_source_emb[i], 0)\n",
        "out_vec = modal_model.predict(vec)\n",
        "ids, _ = index.get_nns_by_vector(out_vec.T, 10, include_distances=True)\n",
        "[test_target_docs[i] for i in ids]"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}